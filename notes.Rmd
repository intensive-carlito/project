---
title: "Air BnB à Paris"
output: html_notebook
---

# La source principale est inside airbnb

* `listings.csv` qui contient l'ensemble des appartements (60 000 appartements)
* `reviews.csv` les revues des clients (1 000 000 de lignes)
* `accessibilite-des-gares-et-stations-metro-et-rer.csv` Les stations 400 stations de métro avec leurs positions.
* `quartiers.rds` : Paris est découpé en 80 quartiers, plus précis que les arrondissements.

* Monuments de Paris sur la base Mérimée (2000 données)
* timeout.fr les cents meilleurs bars de Paris. On peut y faire du scrapping pour récupérer les adresses grace à adresse.data.gouv.fr on peut récupérer les coordonnées GPS.

# Fabrication des quartiers

Nous utilisons https://opendata.paris.fr/explore/dataset/quartier_paris/export/

pour télécharger les quartiers de Paris.

Nous avons exporté les id, latitudes, longitudes des différentes locations au format csv.

Ces deux sources ont été importées dans QGIS. L'outil d'intersection nous a alors permis de déterminer à quels quartiers appartiennent chacune des locations.
Après cette opération, nous avons exporté le résultat dans le fichier `quartiers.csv`.

![QGIS](./images/qgis.png)

# Récupération des monuments

Un peu de scrapbooking sur le site http://monumentsdeparis.net/ permet de récupérer les monuments parisiens ainsi que leurs adresses.
Une seconde étape est d'utiliser à nouveau adresse.data.gouv.fr pour récupérer les adresses dans un format harmonisé et les longitudes/latitudes.

Ensuite, pour chaque logement, on compte combien de monuments sont à moins de 100, 200m, 500m et 1km.
Le résultat est stocké dans la table `P04_dist_monuments`.


# Premiers essais

## La base Air BnB seule

On a pris quelques champs donnés par la base Air BnB seule, on les a nettoyés puis on a fait une randomforest dessus.

Le bilan est qu'on obtient deux composantes importantes qui sont *la longueur de la présentation de l'appartement* et *l'ancienneté de l'appartement sur Air BnB*
On peut expliquer que le nombre de mots change beaucoup et il y a presque autant de cas que d'appartements présentés, ça peut expliquer un peu la représentativité.
Idem pour le délai d'existence.

On a ensuite fait des tranches de prix et transformé ces prix en factors.
L'erreur est à 80%.

On a regardé la répartition des prix par lieu dans deux cas :

* appartement pour 2 personnes
* tous les appartements

On constate que ce serait sûrement intéressant de faire une classification avant de faire le modèle.


# Pense-bête

* Création d'un property_type plus propre en ajoutant un *Divers*
* Traductions automatiques
* ammenities à nettoyer et regarder ce qu'on peut en tirer
* positivité des messages / commentaires

# Répartition du travail

## Charles

R Shiny : première application avec des onglets

## Mathieu

Web scrapping pour les bars et les monuments.

## David

* Traduction des commentaires
* Analyse des sentiments

```curl -XPOST "https://translate.yandex.net/api/v1.5/tr.json/translate?key=trnsl.1.1.20181214T151349Z.e323c6a0eeb6c59d.6ed57788f95d2a05d4269fddb847986f8769b990&text=ce%20chat%20est%20mignon&lang=fr-en&format=plain"```

fait la traduction de *Ce chat est mignon* en *this cat is cute*.

Problème rencontré : Lors d'une utilisation massive de la fonction `translate` dans une datatable, il arrive un moment où R Studio crashe.
Pour palier à ce problème, j'ai fait un petit programme en Go qui fait le même travail.

